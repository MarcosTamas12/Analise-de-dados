{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "861496e8",
   "metadata": {},
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad871dcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MARCOS~1\\AppData\\Local\\Temp/ipykernel_15528/637800710.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEllipse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "import statistics as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import variation\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import zip_longest\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b46963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('ticdata2000.txt',sep='\\t', header=None)\n",
    "df_eval = pd.read_csv('ticeval2000.txt',sep='\\t', header=None)\n",
    "df_tgts = pd.read_csv('tictgts2000.txt',sep='\\t', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853c2e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ea787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa6b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tgts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a62bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = ['0', '1', '2', '3',  '4',  '5',  '6',  '7',  '8',  '9', '10', '11', '12', '13', '14', '15', '16', '17',\n",
    "#            '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34',\n",
    "#            '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51',\n",
    "#            '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68',\n",
    "#            '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84']\n",
    "#y = ['85']\n",
    "X = [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
    "            68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
    "\n",
    "\n",
    "y = 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca570251",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_data[85].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3323d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data[X], df_data[y], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c627b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_data[X]\n",
    "outcome = df_data[y]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(df_data[X], df_data[y])\n",
    "knn.predict(df_eval)\n",
    "print (knn.predict_proba(df_eval))\n",
    "\n",
    "fitted = knn.predict(df_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob= knn.predict_proba(df_eval)\n",
    "prob = prob[:, 1]\n",
    "print('Recall = ', recall_score(df_tgts, fitted, average='macro'))\n",
    "\n",
    "print('Precision = ' ,precision_score(df_tgts, fitted, average='macro'))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df_tgts, fitted, pos_label=2)\n",
    "print('AUC = ', metrics.roc_auc_score(df_tgts, prob))\n",
    "\n",
    "\n",
    "def plot_roc_curve(fper, tper):\n",
    "    plt.plot(fper, tper, color='red', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fper, tper, thresholds = roc_curve(df_tgts, prob)\n",
    "plot_roc_curve(fper, tper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(df_tgts, fitted).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e537163",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(df_tgts, fitted)\n",
    "print('Precision', conf_mat[0, 0] / sum(conf_mat[:, 0]))\n",
    "print('Recall', conf_mat[0, 0] / sum(conf_mat[0, :]))\n",
    "print('Specificity', conf_mat[1, 1] / sum(conf_mat[1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_data[X]\n",
    "outcome = df_data[y]\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=1, \n",
    "                            oob_score=True)\n",
    "rf.fit(predictors, outcome)\n",
    "print(rf.oob_decision_function_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_data[X]\n",
    "outcome = df_data[y]\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic', subsample=.63, \n",
    "                    use_label_encoder=False, eval_metric='error')\n",
    "print(xgb.fit(predictors, outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e649746",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator = list(range(20, 510, 5))\n",
    "oobScores = []\n",
    "for n in n_estimator:\n",
    "    rf = RandomForestClassifier(n_estimators=n, \n",
    "                                criterion='entropy',\n",
    "                                random_state=13, oob_score=True)\n",
    "    rf.fit(predictors, outcome)\n",
    "    oobScores.append(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a79c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'n': n_estimator, \n",
    "    'oobScore': oobScores\n",
    "}).plot(x='n', y='oobScore', legend=False, title='Nº Estimadores(Árvores) x Taxa de Erro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
    "            68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
    "outcome = 85\n",
    "\n",
    "X = pd.get_dummies(df_data[predictors], drop_first=True)\n",
    "y = pd.Series([1 if o == 'default' else 0 for o in df_data[outcome]])\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=5000)\n",
    "\n",
    "xgb_default = XGBClassifier(objective='binary:logistic', n_estimators=250, max_depth=6,\n",
    "                            reg_lambda=0, learning_rate=0.3, subsample=1,\n",
    "                            use_label_encoder=False, eval_metric='error')\n",
    "xgb_default.fit(train_X, train_y)\n",
    "\n",
    "xgb_penalty = XGBClassifier(objective='binary:logistic', n_estimators=250, max_depth=6,\n",
    "                            reg_lambda=1000, learning_rate=0.1, subsample=0.63,\n",
    "                            use_label_encoder=False, eval_metric='error')\n",
    "print(xgb_penalty.fit(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_default = xgb_default.predict_proba(train_X)[:, 1]\n",
    "error_default = abs(train_y - pred_default) > 0.5\n",
    "print('default (train): ', np.mean(error_default))\n",
    "\n",
    "pred_default = xgb_default.predict_proba(valid_X)[:, 1]\n",
    "error_default = abs(valid_y - pred_default) > 0.5\n",
    "print('default: ', np.mean(error_default))\n",
    "\n",
    "pred_penalty = xgb_penalty.predict_proba(valid_X)[:, 1]\n",
    "error_penalty = abs(valid_y - pred_penalty) > 0.5\n",
    "print('penalty: ', np.mean(error_penalty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917108c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for ntree_limit in range(1, 250):\n",
    "    train_default = xgb_default.predict_proba(train_X, iteration_range=(1, ntree_limit))[:, 1]\n",
    "    train_penalty = xgb_penalty.predict_proba(train_X, iteration_range=(1, ntree_limit))[:, 1]\n",
    "    pred_default = xgb_default.predict_proba(valid_X, iteration_range=(1, ntree_limit))[:, 1]\n",
    "    pred_penalty = xgb_penalty.predict_proba(valid_X, iteration_range=(1, ntree_limit))[:, 1]\n",
    "    results.append({\n",
    "        'iterations': ntree_limit,\n",
    "        'default train': np.mean(abs(train_y - train_default) > 0.5),\n",
    "        'penalty train': np.mean(abs(train_y - train_penalty) > 0.5),\n",
    "        'default test': np.mean(abs(valid_y - pred_default) > 0.5),\n",
    "        'penalty test': np.mean(abs(valid_y - pred_penalty) > 0.5),\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277242bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = results.plot(x='iterations', y='default test')\n",
    "results.plot(x='iterations', y='penalty test', ax=ax)\n",
    "results.plot(x='iterations', y='default train', ax=ax)\n",
    "results.plot(x='iterations', y='penalty train', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
    "            68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
    "outcome = 85\n",
    "\n",
    "X = df_data[predictors]\n",
    "y = pd.Series([1 if o == 'default' else 0 for o in df_data[outcome]])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9365152",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(objective='binary:logistic', subsample=.63, use_label_encoder=False)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "pred_y = pred == 1\n",
    "true_y = y_test == 1\n",
    "true_pos = true_y & pred_y\n",
    "true_neg = ~true_y & ~pred_y\n",
    "false_pos = ~true_y & pred_y\n",
    "false_neg = true_y & ~pred_y\n",
    "\n",
    "conf_mat = pd.DataFrame([[np.sum(true_pos), np.sum(false_neg)], [np.sum(false_pos), np.sum(true_neg)]],\n",
    "                       index=['Y = default', 'Y = paid off'],\n",
    "                       columns=['Yhat = default', 'Yhat = paid off'])\n",
    "print(conf_mat.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edee046",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, pred).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test, pred)\n",
    "print('Precision', conf_mat[0, 0] / sum(conf_mat[:, 0]))\n",
    "print('Recall', conf_mat[0, 0] / sum(conf_mat[0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0dc4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, xgb.predict(X_test), \n",
    "                                 pos_label=1)\n",
    "roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d13a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(df_tgts, xgb.predict(df_eval))\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = roc_df.plot(x='specificity', y='recall', figsize=(10, 10), legend=False)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(1, 0)\n",
    "ax.plot((1, 0), (0, 1))\n",
    "ax.set_xlabel('specificity')\n",
    "ax.set_ylabel('recall')\n",
    "ax.fill_between(roc_df.specificity, 0, roc_df.recall, alpha=0.3)\n",
    "ax.text(.5,.5,'AUC: %.3f' % (auc*100),\n",
    "          bbox={'facecolor':'white','alpha':1,'edgecolor':'none','pad':1},\n",
    "          ha='center', va='center')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875de663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictors = [0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
    "            68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
    "outcome = 85\n",
    "\n",
    "X = pd.get_dummies(df_data[predictors], drop_first=True)\n",
    "y = df_data[outcome]\n",
    "\n",
    "rf_all = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "rf_all.fit(X, y)\n",
    "\n",
    "rf_all_entropy = RandomForestClassifier(n_estimators=500, random_state=1,\n",
    "                                        criterion='entropy')\n",
    "print(rf_all_entropy.fit(X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac21240",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "scores = defaultdict(list)\n",
    " \n",
    "# crossvalidate the scores on a number of different random splits of the data\n",
    "for _ in range(3):\n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(X, y, \n",
    "                                                          test_size=0.3)\n",
    "    rf.fit(train_X, train_y)\n",
    "    acc = metrics.accuracy_score(valid_y, rf.predict(valid_X))\n",
    "    for column in X.columns:\n",
    "        X_t = valid_X.copy()\n",
    "        X_t[column] = np.random.permutation(X_t[column].values)\n",
    "        shuff_acc = metrics.accuracy_score(valid_y, rf.predict(X_t))\n",
    "        scores[column].append((acc-shuff_acc)/acc)\n",
    "print('Features sorted by their score:')\n",
    "print(sorted([(round(np.mean(score), 4), feat) for\n",
    "              feat, score in scores.items()], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_all.feature_importances_\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'feature': X.columns, \n",
    "    'Accuracy decrease': [np.mean(scores[column]) for column in \n",
    "                         X.columns],\n",
    "    'Gini decrease': rf_all.feature_importances_, \n",
    "    'Entropy decrease': rf_all_entropy.feature_importances_,\n",
    "})\n",
    "df = df.sort_values('Accuracy decrease')\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 10))\n",
    "ax = df.plot(kind='barh', x='feature', y='Accuracy decrease', \n",
    "             legend=False, ax=axes[0])\n",
    "ax.set_ylabel('')\n",
    "\n",
    "ax = df.plot(kind='barh', x='feature', y='Gini decrease', \n",
    "             legend=False, ax=axes[1])\n",
    "ax.set_ylabel('')\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef291062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
